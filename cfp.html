<!DOCTYPE html>
<html lang="en-US">
  <head>

    
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Trustworthy and Reliable Large-Scale Machine Learning Models | Workshop at ICLR 2023</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Trustworthy and Reliable Large-Scale Machine Learning Models" />
<meta property="og:locale" content="en_US" />
<meta name="description" content=" Workshop at ICLR 2023" />
<meta property="og:description" content="Workshop at ICLR 2023" />
<meta property="og:site_name" content="Trustworthy and Reliable Large-Scale Machine Learning Models" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Trustworthy and Reliable Large-Scale Machine Learning Models" />
<script type="application/ld+json">
  {"headline":"Trustworthy and Reliable Large-Scale Machine Learning Models","url":"/cfp.html","name":"Trustworthy and Reliable Large-Scale Machine Learning Models","description":"Workshop at ICLR 2023","@type":"WebSite","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=">
  </head>
  <body>
  <a id="skip-to-content" href="#content">Skip to the content.</a>

  <header class="page-header" role="banner">
    <h1 class="project-name">Trustworthy and Reliable Large-Scale Machine Learning Models</h1>
    <h2 class="project-tagline">Workshop at ICLR 2023</h2>


    <a href="/" class="btn">Home</a>

    <a href="/cfp.html" class="btn">Call for Papers</a>

    <!--      <a href="/rtml-iclr2023/papers.html" class="btn">Accepted Papers</a>-->

    <a href="/schedule.html" class="btn">Schedule</a>

    <a href="/speakers.html" class="btn">Speakers</a>

    <a href="/organizers.html" class="btn">Organizers</a>

    <a href="/committee.html" class="btn">Program Committee</a>

    <a href="/related.html" class="btn">Related Workshops</a>

    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="call-for-papers">Call for Papers</h1>

<style>
.foo {
    table-layout: fixed;
    width: 100%;
}
</style>

<table class="foo">  
  <tr>
    <td width="30%"><b>Submission Deadline</b></td>
    <td width="70%"><strike>March 24</strike> March 31, 2023 Anywhere on Earth (AoE)</td>
  </tr>
  <tr>
    <td><b>Author notification</b></td>
    <td>April 14, 2023 Anywhere on Earth (AoE)</td>
  </tr>
  <tr>
    <td><b>Camera ready deadline</b></td>
    <td>April 21, 2023 Anywhere on Earth (AoE)</td>
  </tr>
  <tr>
    <td><b>Submission server</b></td>
    <td>
    <a href="https://openreview.net/group?id=ICLR.cc/2023/Workshop/RTML">https://openreview.net/group?id=ICLR.cc/2023/Workshop/RTML</a>

    </td>
  </tr>
  <tr>
    <td><b>Submission format</b></td>
    <td>Submissions need to be anonymized, and use the latex template <a href="https://drive.google.com/open?id=12KghPlnaTUUwLEb35IckuGG_ilE4Elzc&authuser=boxinw2%40illinois.edu&usp=drive_fs">here</a>, modified from the template for ICLR conference papers. Submissions should include at most <b>4</b> pages, excluding the references and appendices.</td>
  </tr>  
</table>

<p>We invite submissions on any aspect of trustworthy and reliable ML, especially for large-scale models. Topics include but are not limited to:</p>

<ul>
  <li>Novel methods for building more trustworthy large-scale machine learning models that prevent or alleviate negative societal impacts of existing ML methods</li>
  <li>New applications and settings where the robustness and trustworthiness of machine learning play an important role and how well existing techniques work under these settings</li>
  <li>Machine learning models with verifiable guarantees (such as robustness, fairness, and privacy guarantees) to build trustworthiness</li>
  <li>Privacy-preserving machine learning approaches for large-scale machine learning models</li>
  <li>Theoretical understanding of trustworthy machine learning</li>
  <li>Explainable and interpretable methods for large-scale AI</li>
  <li>Pre-training techniques to build more robust and trustworthy large-scale machine learning models</li>
  <li>Efficient fine-tuning methods to alleviate the trustworthiness gap for large-scale pre-trained models</li>
  <li>Machine unlearning to mitigate the privacy, toxicity, and bias issues within large-scale AI models</li>
  <li>Robust decision-making under uncertainty</li>
  <li>Futuristic concerns about trustworthy machine learning for foundation models</li>
  <li>Game-theoretic analysis for socially responsible machine learning systems</li>
  <li>Case studies and field research of the societal impacts of applying machine learning in mission-critical and human-centric tasks</li>
</ul>

<p>We only consider submissions that haven’t been published in any peer-reviewed venue, including ICLR 2023 conference. The workshop is non-archival and will not have any official proceedings. Based on the PC’s recommendation, the accepted papers will be allocated either a contributed talk or a poster presentation.</p>

<p><b>We offer a Best Paper Award ($1,000), a Best Paper Honorable Mention Award ($500), and several travel grants (complimentary ICLR conference registrations).</b></p>


      <footer class="site-footer">
        <span class="site-footer-credits">Please contact <a href="mailto:Yu.Cheng@microsoft.com">Yu Cheng</a>  or <a href="mailto:boxinw2@illinois.edu">Boxin Wang</a> if you have any questions.<br> The webpage template is by the courtesy of <a href="https://tda-in-ml.github.io/">NeurIPS 2020 Workshop on Topological Data Analysis and Beyond</a>. <br>
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>
          on Wed, 01 Feb 2023 20:33:05.
        </span>
      </footer>
    </main>
  </body>
</html>
