<!DOCTYPE html>
<html lang="en-US">
  <head>

    
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Trustworthy and Reliable Large-Scale Machine Learning Models | Workshop at ICLR 2023</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Trustworthy and Reliable Large-Scale Machine Learning Models" />
<meta property="og:locale" content="en_US" />
<meta name="description" content=" Workshop at ICLR 2023" />
<meta property="og:description" content="Workshop at ICLR 2023" />
<meta property="og:site_name" content="Trustworthy and Reliable Large-Scale Machine Learning Models" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Trustworthy and Reliable Large-Scale Machine Learning Models" />
<script type="application/ld+json">
{"headline":"Trustworthy and Reliable Large-Scale Machine Learning Models","url":"/","name":"Trustworthy and Reliable Large-Scale Machine Learning Models","description":"Workshop at ICLR 2023","@type":"WebSite","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=">
  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Trustworthy and Reliable Large-Scale Machine Learning Models</h1>
      <h2 class="project-tagline">Workshop at ICLR 2023</h2>
      
      
      <a href="/" class="btn">Home</a>
      
      <a href="/cfp.html" class="btn">Call for Papers</a>
      
<!--      <a href="/rtml-iclr2023/papers.html" class="btn">Accepted Papers</a>-->
      
      <a href="/schedule.html" class="btn">Schedule</a>
      
      <a href="/speakers.html" class="btn">Speakers</a>
      
      <a href="/organizers.html" class="btn">Organizers</a>
      
      <a href="/committee.html" class="btn">Program Committee</a>
      
      <a href="/related.html" class="btn">Related Workshops</a>
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="overview">Overview</h1>

<table>
  <tbody>
    <tr>
      <td><strong>Date</strong></td>
      <td>May 5, 2023</td>
    </tr>
    <tr>
      <td><strong>Location</strong></td>
      <td>The workshop will be held in a <em>Hybrid</em> mode, welcoming both in-person and virtual attendance (<a href="https://iclr.cc/">ICLR registration</a> required).</td>
    </tr>
  </tbody>
</table>

      <p>In recent years, the landscape of AI has been significantly altered by the advances in large-scale pre-trained models. Scaling up the models with more data and parameters has significantly improved performance and achieved great success in a variety of applications, from natural language understanding to multi-modal representation learning. However, when applying large-scale AI models to real-world applications, there have been concerns about their potential security, privacy, fairness, robustness, and ethics issues. In the wrong hands, machine learning could be used to negatively impact mission-critical domains, including healthcare, education, and law, resulting in economic and environmental consequences as well as legal and ethical concerns. For example, existing studies have shown that large-scale pre-trained language models contain toxicity in open-ended generation and have the risk of amplifying bias against marginalized groups, such as BIPOC and LGBTQ+. Moreover, large-scale models can unintentionally leak sensitive personal information during the pre-training stage. Last but not least, machine learning models are often viewed as "blackboxes" and may produce unpredictable, inaccurate, and unexplainable results, especially under domain shifts or maliciously tailored attacks. </p>

      <p>To address these negative societal impacts in large-scale models, researchers have investigated different approaches and principles to ensure robust and trustworthy large-scale AI systems. This workshop is the first attempt to bridge the gap between security, privacy, fairness, ethics, and large-scale AI models and aims to discuss the principles and experiences of developing robust and trustworthy large-scale AI systems. The workshop also focuses on how future researchers and practitioners should prepare themselves to reduce the risks of unintended behaviors of large ML models. </p>

      <p>This workshop aims to bring together researchers interested in the emerging and interdisciplinary field of robustness and trustworthiness in large-scale foundation models from a broad range of disciplines with different perspectives on this problem. We attempt to highlight recent related work from different communities, clarify the foundations of trustworthy machine learning, and chart out important directions for future work and cross-community collaborations. </p>
<!--<h1 id="paper-awards">Paper Awards</h1>-->

<!--<h2 id="best-paper-award">Best Paper Award</h2>-->

<!--<ul>-->
<!--  <li><b><a href="https://aisecure-workshop.github.io/rtml-iclr2023/papers/21.pdf">Ditto: Fair and Robust Federated Learning Through Personalization</a></b> <br /> Tian Li (Carnegie Mellon University); Shengyuan Hu (Carnegie Mellon University); Ahmad Beirami (Facebook AI); Virginia Smith (Carnegie Mellon University)</li>-->
<!--</ul>-->

<!--<h2 id="best-paper-honorable-mention-award">Best Paper Honorable Mention Award</h2>-->

<!--<ul>-->
<!--  <li><b><a href="https://aisecure-workshop.github.io/rtml-iclr2023/papers/47.pdf">RobustBench: a standardized adversarial robustness benchmark</a></b> <br /> Francesco Croce (University of Tübingen); Maksym Andriushchenko (EPFL); Vikash Sehwag (Princeton University); Edoardo Debenedetti (EPFL); Nicolas Flammarion (EPFL); Mung Chiang (Princeton University); Prateek Mittal (Princeton University); Matthias Hein (University of Tübingen)</li>-->
<!--</ul>-->

<!--<h2 id="travel-award-recipients">Travel Award Recipients</h2>-->

<!--<ul>-->
<!--  <li>Fartash Faghri (University of Toronto)</li>-->
<!--  <li>Jay Nandy (National University of Singapore)</li>-->
<!--  <li>Mingjie Sun (Carnegie Mellon University)</li>-->
<!--  <li>Linxi Jiang (Fudan University)</li>-->
<!--  <li>Siyue Wang (Northeastern University)</li>-->
<!--  <li>Liam Fowl (University of Maryland)</li>-->
<!--  <li>Seyedeh Hanieh Hashemi (University of Southern California)</li>-->
<!--  <li>Sylvestre-Alvise Rebuffi (DeepMind)</li>-->
<!--  <li>Ingkarat Rak-Amnouykit (Rensselaer Polytechnic Institute)</li>-->
<!--  <li>Wen Shen (Tulane University)</li>-->
<!--  <li>Vasu Singla (University of Maryland)</li>-->
<!--  <li>Daniel Ley (University of Cambridge)</li>-->
<!--  <li>Yoshihiro Okawa (Fujitsu Laboratories Ltd.)</li>-->
<!--  <li>Chong Xiang (Princeton University)</li>-->
<!--  <li>Kyungmin Lee (Agency for defense development)</li>-->
<!--  <li>Mengdi Xu (Carnegie Mellon University)</li>-->
<!--  <li>Can Bakiskan (University of California, Santa Barbara)</li>-->
<!--  <li>Xiangyu Qi (Zhejiang University)</li>-->
<!--  <li>Xiao Zhang (Leiden University)</li>-->
<!--  <li>Guanhong Tao (Purdue University)</li>-->
<!--  <li>Vikash Sehwag (Princeton University)</li>-->
<!--  <li>Dequan Wang (UC Berkeley)</li>-->
<!--  <li>Eitan Borgnia (University of Maryland)</li>-->
<!--  <li>Jaydeep Borkar (Savitribal Phule Pune University)</li>-->
<!--  <li>Mantas Mazeika (UIUC)</li>-->
<!--</ul>-->

<!--<p>The workshop is sponsored by <a href="https://www.openphilanthropy.org/">Open Philanthropy</a>. The funding covers a Best Paper Award ($1,000), a Best Paper Honorable Mention Award ($500), and multiple travel grants (complimentary ICLR conference registrations).</p>-->

<!--<p align="center">-->
<!--	<img src="./assets/images/OpenPhil.png" alt="Open Phil" width="350" />-->
<!--</p>-->


        <footer class="site-footer">
        <span class="site-footer-credits">Please contact <a href="mailto:Yu.Cheng@microsoft.com">Yu Cheng</a>  or <a href="mailto:boxinw2@illinois.edu">Boxin Wang</a> if you have any questions.<br> The webpage template is by the courtesy of <a href="https://tda-in-ml.github.io/">NeurIPS 2020 Workshop on Topological Data Analysis and Beyond</a>. <br>
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>
          on Wed, 01 Feb 2023 20:33:05.
        </span>
        </footer>
    </main>
  </body>
</html>
